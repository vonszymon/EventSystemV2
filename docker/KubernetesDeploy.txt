*********** LOGOWANIE DO APLIKACJI ***********

Login: Admin
Hasło: 123456

*********** BUDOWANIE NOWYCH WERSJI KONTENERÓW (wymagane tylko w przypadku wprowadzenia zmian w aplikacji) ***********

4 kontenery do zbudowania:
userdb - baza użytkowników
eventdb - baza eventów
eventsystem - aplikacja
eventservices - serwisy REST-owe

Żeby zbudować kontenery z eventsystem i eventservices należy do odpowiadających im folderów ( w katalogu docker ) 
skopiować spakowany serwer ( https://drive.google.com/open?id=0B5c935hNCEjLSmU4emNZWTZaWEU ).
Dodatkowo trzeba też wrzucić spakowaną aplikacje i serwisy REST-owe do odpowiadających im folderów: EventSystem.war i eventservices.war.
W repozytorium znajdują się już spakowane wersje, więc ten krok można pominąć o ile nie wykonywane były zmiany w aplikacji.

----------------------------------------------------------------------------------------------------------------------------

WSZYSTKIE KOMENDY PONIŻEJ NALEŻY ODPALAĆ Z TERMINALA ZALOGOWANEGO NA ROOTA (sudo -i)
Google Cloud SDK musi być zainstalowany (https://cloud.google.com/sdk/docs/quickstart-linux)
i skonfigurowany (gcloud init) także z terminala roota.

Uruchamianie dockera:
service docker start

------------ budowanie userdb i pushowanie obrazu do rejestru googla (można nadawać wersje budowanym obrazom) ----------
export PROJECT_ID="iosr-cloud"
docker build -t gcr.io/$PROJECT_ID/userdb:v1 .
gcloud docker push gcr.io/$PROJECT_ID/userdb:v1

------------ budowanie eventdb i pushowanie obrazu do rejestru googla ----------

docker build -t gcr.io/$PROJECT_ID/eventdb:v1 .
gcloud docker push gcr.io/$PROJECT_ID/eventdb:v1

------------ budowanie eventsystem i pushowanie obrazu do rejestru googla ----------

docker build -t gcr.io/$PROJECT_ID/eventsystem:v1 .
gcloud docker push gcr.io/$PROJECT_ID/eventsystem:v1

------------ budowanie eventservices i pushowanie obrazu do rejestru googla ----------

docker build -t gcr.io/$PROJECT_ID/eventservices:v1 .
gcloud docker push gcr.io/$PROJECT_ID/eventservices:v1

************* URUCHAMIANIE APLIKACJI ******************

Uruchamianie poszczególnych kontenerów i exponowanie ich na zewnątrz klastra ( nadanie externalIP ).
Pierwsza komenda tworzy deployment i 1 pod. W podzie odpalany jest kontener. 
Deployment zarządza swoimi podami (jak pod padnie to go zrestartuje na przykład) . 
Możliwe jest stworzenie kilku replik ( podów ) którymi zarządza obiekt deployment ( wystarczy podanie liczby replik przy wywołaniu komendy, z defaultu jest jedna ).
Druga komenda tworzy serwis dla danego deploymentu i nadaje externalIP przez który można się wbijać na niego.

(odpalane z dowolnego katalogu, wcześniej trzeba utworzyć jeden cluster container)
(gcloud containers clusters create iosr-cluster)

kubectl run userdb --image=gcr.io/$PROJECT_ID/userdb:v1 --port=3306
kubectl expose deployment userdb --type="LoadBalancer"

kubectl run eventdb --image=gcr.io/$PROJECT_ID/eventdb:v1 --port=3306
kubectl expose deployment eventdb --type="LoadBalancer"

kubectl run eventservices --image=gcr.io/$PROJECT_ID/eventservices:v1 --port=8080
kubectl expose deployment eventservices --type="LoadBalancer"

kubectl run eventsystem --image=gcr.io/$PROJECT_ID/eventsystem:v1 --port=8080
kubectl expose deployment eventsystem --type="LoadBalancer" --session-affinity="ClientIP"

*************** AUTOSKALOWANIE DEPLOYMENTU ************************

Stworzenie autoskalera dla deploymentu eventservices o minimalnej liczbie podów 3, maks 8 i % CPU przy którym tworzony nowy pod.

kubectl autoscale deployment eventservices --min=3 --max=8 --cpu-percent=20

Stworzenie autoskalera dla deploymentu eventsystem.

kubectl autoscale deployment eventsystem --min=3 --max=5 --cpu-percent=20

*************** TESTY JMETER **************************

W folderze Jmeter znajdują się testy jmeterowe, które można wczytać do guia i odpalić wybrane testy. Należy się upewnić że zmienna przechowująca IP systemu ma poprawną wartość.
Zalecam po odpaleniu testów które dodają eventy/komentarze bądź userów zrestartować odpowiedni pod z bazą, żeby wstała pusta baza bez danych wrzuconych przez test.

kubectl delete pod eventdb_xxx ( po usunięciu poda, deployment automatycznie postawi nowy pod, bo dba żeby zawsze była postawiona określona liczba podów )
kubectl delete pod userdb_xxx

Odpalając np. test dodawania komentarzy można zaobserwować działanie autoskalingu. Przy większym zużyciu CPU autoskaler automatycznie stworzy nowe pody,
a po zakończeniu testów, po jakimś czasie dodatkowe pody zostaną usunięte z powodu braku ruchu.

************ PRZYDATNE KOMENDY ******************

kubectl get deployments/pods/hpa (hpa - autoskalery)
kubectl get services ( można tu sprawdzić external ip serwisów dzięki którym można się na nie wbić )
kubectl delete ( deployment/service/hpa ) xxx
kubectl logs pod_name
